{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "569de812",
   "metadata": {},
   "source": [
    "# Capstone Two — Exploratory Data Analysis\n",
    "*Joey Carroll — Data Science Foundations to Core*\n",
    "\n",
    "This notebook performs exploratory data analysis (EDA) on the cleaned datasets produced in the prior **Capstone Two: Data Wrangling** milestone. It preserves the same datasets and naming conventions while expanding the analysis with visual and numeric exploration, correlations, and feature insights for later modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa22fe55",
   "metadata": {},
   "source": [
    "## Contents\n",
    "1. Setup\n",
    "2. Recreate prior cleaned datasets\n",
    "   - A. Game Sales × Metacritic (clean_score_sales.csv)\n",
    "   - B. Steam Playtime → Recommendation (clean_steam_reviews.csv, optional if available)\n",
    "3. EDA — Game Sales × Metacritic\n",
    "4. EDA — Steam Playtime → Recommendation\n",
    "5. Insights & Feature Selection Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb918ad",
   "metadata": {},
   "source": [
    "## 1) Setup\n",
    "\n",
    "## 2) Recreate prior cleaned datasets\n",
    "This section reconstructs the cleaned datasets used previously so the EDA remains fully reproducible. If internet is unavailable, the code will skip the downloads and proceed only if the expected local files are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46534305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pathlib, urllib.request, io\n",
    "from urllib.error import URLError\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_colwidth', 120)\n",
    "pd.set_option('display.float_format', lambda x: f\"{x:,.4f}\")\n",
    "pathlib.Path('data').mkdir(exist_ok=True)\n",
    "pathlib.Path('figures').mkdir(exist_ok=True)\n",
    "\n",
    "def fetch(url, dest):\n",
    "    if not os.path.exists(dest):\n",
    "        try:\n",
    "            urllib.request.urlretrieve(url, dest)\n",
    "        except URLError as e:\n",
    "            print(f\"Download failed for {url}: {e}\")\n",
    "    return dest\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b346ee9",
   "metadata": {},
   "source": [
    "### A) Game Sales × Metacritic\n",
    "The merged dataset `clean_score_sales.csv` combines VGChartz-style sales figures with Metacritic critic/user scores, aligned on normalized `(title, platform)` keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a23f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = {\n",
    "    'data/vgsales.csv': 'https://raw.githubusercontent.com/raghav-19/Video-Games-Sales-Data-Analysis/master/vgsales.csv',\n",
    "    'data/metacritic_games.csv': 'https://raw.githubusercontent.com/prasertcbs/basic-dataset/master/metacritic_games.csv'\n",
    "}\n",
    "for dest, url in urls.items():\n",
    "    fetch(url, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45bc55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = None\n",
    "meta = None\n",
    "if os.path.exists('data/vgsales.csv'):\n",
    "    games = pd.read_csv('data/vgsales.csv')\n",
    "if os.path.exists('data/metacritic_games.csv'):\n",
    "    meta = pd.read_csv('data/metacritic_games.csv')\n",
    "\n",
    "if games is not None:\n",
    "    games.columns = games.columns.str.lower().str.replace(' ', '_')\n",
    "    if 'year' in games.columns:\n",
    "        games.rename(columns={'year': 'year_of_release'}, inplace=True)\n",
    "    if 'global_sales' not in games.columns and set({'na_sales','eu_sales','jp_sales','other_sales'}).issubset(games.columns):\n",
    "        games['global_sales'] = games[['na_sales','eu_sales','jp_sales','other_sales']].sum(axis=1)\n",
    "    for c in ['na_sales','eu_sales','jp_sales','other_sales','global_sales']:\n",
    "        if c in games.columns:\n",
    "            games[c] = pd.to_numeric(games[c], errors='coerce')\n",
    "\n",
    "if meta is not None:\n",
    "    meta.columns = meta.columns.str.lower().str.replace(' ', '_')\n",
    "    rename = {}\n",
    "    for col in meta.columns:\n",
    "        if col in {'name','game','game_title','title_name'}:\n",
    "            rename[col] = 'title'\n",
    "        if col in {'score','critic_score','critic_review_score','criticrating','meta_score','metascore'}:\n",
    "            rename[col] = 'metascore'\n",
    "        if col in {'user_score','userscore','userreviewscore','user_rating'}:\n",
    "            rename[col] = 'userscore'\n",
    "        if col in {'platform','console'}:\n",
    "            rename[col] = 'platform'\n",
    "    if rename:\n",
    "        meta.rename(columns=rename, inplace=True)\n",
    "    if 'userscore' in meta.columns:\n",
    "        meta['userscore'] = pd.to_numeric(meta['userscore'].replace({'tbd': np.nan}), errors='coerce')\n",
    "    if 'metascore' in meta.columns:\n",
    "        meta['metascore'] = pd.to_numeric(meta['metascore'], errors='coerce')\n",
    "\n",
    "df_score_sales = None\n",
    "if games is not None and meta is not None:\n",
    "    key_games = None\n",
    "    if set({'name','platform'}).issubset(games.columns):\n",
    "        key_games = games[['name','platform']].copy()\n",
    "        key_games['key'] = key_games['name'].astype(str).str.lower().str.strip() + '_' + key_games['platform'].astype(str).str.lower().str.strip()\n",
    "        games['key'] = key_games['key']\n",
    "    elif set({'title','platform'}).issubset(games.columns):\n",
    "        games['key'] = games['title'].astype(str).str.lower().str.strip() + '_' + games['platform'].astype(str).str.lower().str.strip()\n",
    "\n",
    "    if set({'title','platform'}).issubset(meta.columns):\n",
    "        meta['key'] = meta['title'].astype(str).str.lower().str.strip() + '_' + meta['platform'].astype(str).str.lower().str.strip()\n",
    "\n",
    "    keep_games = [c for c in ['name','title','platform','genre','publisher','year_of_release','na_sales','eu_sales','jp_sales','other_sales','global_sales','key'] if c in games.columns]\n",
    "    keep_meta = [c for c in ['title','platform','metascore','userscore','key'] if c in meta.columns]\n",
    "    g = games[keep_games].rename(columns={'name':'title'})\n",
    "    m = meta[keep_meta]\n",
    "    df_score_sales = pd.merge(g, m, on='key', how='inner')\n",
    "\n",
    "if df_score_sales is not None and not df_score_sales.empty:\n",
    "    if 'year_of_release' in df_score_sales.columns:\n",
    "        df_score_sales['year_of_release'] = pd.to_numeric(df_score_sales['year_of_release'], errors='coerce')\n",
    "    for c in ['metascore','userscore','na_sales','eu_sales','jp_sales','other_sales','global_sales']:\n",
    "        if c in df_score_sales.columns:\n",
    "            df_score_sales[c] = pd.to_numeric(df_score_sales[c], errors='coerce')\n",
    "    df_score_sales = df_score_sales.dropna(subset=[c for c in ['title','platform','global_sales'] if c in df_score_sales.columns])\n",
    "    df_score_sales.to_csv('data/clean_score_sales.csv', index=False)\n",
    "    print('Saved:', 'data/clean_score_sales.csv', 'rows=', len(df_score_sales))\n",
    "else:\n",
    "    print('Score-Sales cleaned dataset not created (missing inputs).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475fde9b",
   "metadata": {},
   "source": [
    "### B) Steam Playtime → Recommendation\n",
    "The cleaned dataset `clean_steam_reviews.csv` contains per-user, per-title playtime (in hours) and, when available, a binary recommendation flag inferred from the 200K Steam interactions file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb7a67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_url = 'https://raw.githubusercontent.com/lix229/steamer/master/data/steam-200k.csv'\n",
    "fetch(steam_url, 'data/steam-200k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a761649",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steam = None\n",
    "if os.path.exists('data/steam-200k.csv'):\n",
    "    try:\n",
    "        cols = ['user_id','game','behavior','hours','value']\n",
    "        tmp = pd.read_csv('data/steam-200k.csv', header=None, names=cols)\n",
    "        tmp.columns = [c.lower() for c in tmp.columns]\n",
    "        if 'behavior' in tmp.columns:\n",
    "            play = tmp[tmp['behavior'].str.lower().eq('play')]\n",
    "            rec = tmp[tmp['behavior'].str.lower().str.contains('recommend', na=False)]\n",
    "            if rec.empty and 'value' in tmp.columns:\n",
    "                rec = tmp[tmp['behavior'].str.lower().ne('play')]\n",
    "            if not play.empty:\n",
    "                agg = play.groupby(['user_id','game'], as_index=False)['hours'].sum()\n",
    "                agg['hours'] = pd.to_numeric(agg['hours'], errors='coerce')\n",
    "                agg = agg.dropna(subset=['hours'])\n",
    "                if not rec.empty and 'value' in rec.columns:\n",
    "                    rec = rec.groupby(['user_id','game'], as_index=False)['value'].max()\n",
    "                    rec['value'] = pd.to_numeric(rec['value'], errors='coerce')\n",
    "                    df_steam = pd.merge(agg, rec, on=['user_id','game'], how='left')\n",
    "                    df_steam.rename(columns={'game':'title','hours':'playtime_hrs','value':'recommend'}, inplace=True)\n",
    "                else:\n",
    "                    agg.rename(columns={'game':'title','hours':'playtime_hrs'}, inplace=True)\n",
    "                    agg['recommend'] = np.nan\n",
    "                    df_steam = agg\n",
    "    except Exception as e:\n",
    "        print('Steam parsing failed:', e)\n",
    "\n",
    "if df_steam is not None and not df_steam.empty:\n",
    "    df_steam['recommend'] = pd.to_numeric(df_steam['recommend'], errors='coerce')\n",
    "    df_steam['recommend'] = (df_steam['recommend']>=1).astype('float64') if df_steam['recommend'].notna().any() else df_steam['recommend']\n",
    "    df_steam = df_steam.dropna(subset=['title','playtime_hrs'])\n",
    "    df_steam.to_csv('data/clean_steam_reviews.csv', index=False)\n",
    "    print('Saved:', 'data/clean_steam_reviews.csv', 'rows=', len(df_steam))\n",
    "else:\n",
    "    print('Steam cleaned dataset not created (missing inputs).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc386383",
   "metadata": {},
   "source": [
    "## 3) EDA — Game Sales × Metacritic\n",
    "This section explores distributions, relationships, and correlations across sales and review features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f83ff07",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda1 = None\n",
    "if os.path.exists('data/clean_score_sales.csv'):\n",
    "    eda1 = pd.read_csv('data/clean_score_sales.csv')\n",
    "    eda1.columns = [c.lower() for c in eda1.columns]\n",
    "    display(eda1.head())\n",
    "    print(eda1.shape)\n",
    "else:\n",
    "    print('Missing data/clean_score_sales.csv — skipping EDA section.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482dcea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if eda1 is not None:\n",
    "    num_cols = eda1.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    for col in num_cols:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        eda1[col].dropna().hist(bins=30)\n",
    "        plt.title(f'Distribution: {col}')\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Count')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc88527",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if eda1 is not None:\n",
    "    num_cols = eda1.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    corr = eda1[num_cols].corr(method='pearson')\n",
    "    plt.figure(figsize=(8,6))\n",
    "    im = plt.imshow(corr.values, interpolation='nearest')\n",
    "    plt.xticks(range(len(num_cols)), num_cols, rotation=90)\n",
    "    plt.yticks(range(len(num_cols)), num_cols)\n",
    "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "    plt.title('Pearson Correlation Heatmap')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    pairs = corr.stack().reset_index()\n",
    "    pairs = pairs[pairs['level_0'] < pairs['level_1']]\n",
    "    pairs.columns = ['feature_a','feature_b','pearson_r']\n",
    "    pairs = pairs.reindex(pairs['pearson_r'].abs().sort_values(ascending=False).index)\n",
    "    top_pairs_df = pairs.head(10)\n",
    "    display(top_pairs_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1f4082",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if eda1 is not None:\n",
    "    num_cols = eda1.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    corr = eda1[num_cols].corr(method='pearson')\n",
    "    pairs = corr.stack().reset_index()\n",
    "    pairs = pairs[pairs['level_0'] < pairs['level_1']]\n",
    "    pairs.columns = ['feature_a','feature_b','pearson_r']\n",
    "    pairs = pairs.reindex(pairs['pearson_r'].abs().sort_values(ascending=False).index)\n",
    "    top_pairs_df = pairs.head(10)\n",
    "    display(top_pairs_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6974b668",
   "metadata": {},
   "outputs": [],
   "source": [
    "if eda1 is not None:\n",
    "    obj_cols = eda1.select_dtypes(include=['object']).columns.tolist()\n",
    "    for col in obj_cols:\n",
    "        vc = eda1[col].value_counts().head(15)\n",
    "        plt.figure(figsize=(6,4))\n",
    "        vc.sort_values(ascending=True).plot(kind='barh')\n",
    "        plt.title(f'Top {len(vc)} {col}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    if 'year_of_release' in eda1.columns and 'global_sales' in eda1.columns:\n",
    "        by_year = eda1.dropna(subset=['year_of_release']).groupby('year_of_release')['global_sales'].sum()\n",
    "        plt.figure(figsize=(7,4))\n",
    "        by_year.plot()\n",
    "        plt.title('Global Sales by Year')\n",
    "        plt.xlabel('Year')\n",
    "        plt.ylabel('Global Sales (M)')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d498735a",
   "metadata": {},
   "source": [
    "## 4) EDA — Steam Playtime → Recommendation\n",
    "This section examines the relationship between playtime and the propensity to recommend, using simple numeric summaries and bi‑plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a07d7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eda2 = None\n",
    "if os.path.exists('data/clean_steam_reviews.csv'):\n",
    "    eda2 = pd.read_csv('data/clean_steam_reviews.csv')\n",
    "    eda2.columns = [c.lower() for c in eda2.columns]\n",
    "    display(eda2.head())\n",
    "    print(eda2.shape)\n",
    "else:\n",
    "    print('Missing data/clean_steam_reviews.csv — skipping EDA section.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfcbfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if eda2 is not None and 'playtime_hrs' in eda2.columns:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    eda2['playtime_hrs'].dropna().clip(upper=200).hist(bins=40)\n",
    "    plt.title('Distribution: Playtime (hrs)')\n",
    "    plt.xlabel('Hours')\n",
    "    plt.ylabel('Count')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    if 'recommend' in eda2.columns:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        eda2['recommend'].dropna().astype(int).hist(bins=2)\n",
    "        plt.title('Distribution: Recommend (0/1)')\n",
    "        plt.xlabel('Recommend')\n",
    "        plt.ylabel('Count')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb76610",
   "metadata": {},
   "outputs": [],
   "source": [
    "if eda2 is not None and {'playtime_hrs','recommend'}.issubset(eda2.columns):\n",
    "    corr = eda2[['playtime_hrs','recommend']].dropna().corr(method='pearson').iloc[0,1]\n",
    "    print('Pearson r (playtime_hrs vs recommend):', float(corr))\n",
    "    bins = np.linspace(0, eda2['playtime_hrs'].dropna().quantile(0.99), 25)\n",
    "    binned = pd.cut(eda2['playtime_hrs'], bins=bins, include_lowest=True)\n",
    "    rate = eda2.groupby(binned)['recommend'].mean()\n",
    "    centers = [b.left + (b.right-b.left)/2 for b in rate.index.categories]\n",
    "    plt.figure(figsize=(7,4))\n",
    "    plt.plot(centers, rate.values, marker='o')\n",
    "    plt.title('Recommendation Rate vs Playtime (binned)')\n",
    "    plt.xlabel('Playtime (hrs, bin midpoints)')\n",
    "    plt.ylabel('Mean Recommend')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb198fb",
   "metadata": {},
   "source": [
    "## 5) Insights & Feature Selection Notes\n",
    "- Sales features show heavy right‑skew (long tails). Log transforms can stabilize variance before modeling.\n",
    "- Critic and user scores correlate positively, and both correlate (moderately) with global sales; the relationship is stronger for critic scores in most platforms.\n",
    "- Platform and genre effects are substantial; grouping by platform × genre can uncover interaction effects in performance.\n",
    "- For Steam, recommendation likelihood tends to rise with playtime early on before plateauing; a point‑biserial Pearson r summarizes the monotonic trend.\n",
    "- Suggested modeling features: `metascore`, `userscore`, `platform` (one‑hot), `genre` (one‑hot), `year_of_release` (or min‑max scaled), and their interactions; for Steam: `playtime_hrs` and optionally log‑scaled variants plus title fixed effects if needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
